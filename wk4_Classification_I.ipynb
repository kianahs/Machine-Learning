{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kianahs/Machine-Learning/blob/main/wk4_Classification_I.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Introduction\n",
        "\n",
        "The aim of this lab is to get familiar with **classification problems** and **logistic regression**. We will be using some code extracts that were implemented last week and build a logistic regression model.\n",
        "\n",
        "1.   This lab is part of Assignment 1 part 2.\n",
        "2.   A report answering the <font color = 'red'>**questions in</font><font color = \"maroon\"> red**</font> should be submitted on QMplus along with the completed Notebooks.\n",
        "3. A single pdf report should be submitted on QMplus along with the completed Notebooks **for both** this and the Neural Networks notebook (lab 6).\n",
        "4. The deadline for **both** is **Friday, 17 November 11:59pm**\n",
        "5. The report should be a separate file in **pdf format** (so **NOT** *doc, docx, notebook* etc.), well identified with your name, student number, assignment number (for instance, Assignment 1), module code.\n",
        "6. Make sure that **any figures or code** you comment on, are **included in the report**.\n",
        "7. No other means of submission other than the appropriate QM+ link is acceptable at any time (so NO email attachments, etc.)\n",
        "8. **PLAGIARISM** <ins>is an irreversible non-negotiable failure in the course</ins> (if in doubt of what constitutes plagiarism, ask!).\n",
        "\n",
        "\n",
        "For this lab, we will be using the [iris dataset](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset)."
      ],
      "metadata": {
        "id": "mwHvxelmCTao"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9KOXH0lw4UC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from sklearn import model_selection\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from IPython import display\n",
        "\n",
        "import typing\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_db = datasets.load_iris(as_frame=True)\n",
        "sn.pairplot(iris_db.data)"
      ],
      "metadata": {
        "id": "lMo6kKqjD0jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_db.data.head(10)"
      ],
      "metadata": {
        "id": "F_TO-d1BEGQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split the data into train and test sets. For consistency and to allow for meaningful comparison the same splits are maintained in the remainder of the lab."
      ],
      "metadata": {
        "id": "TjdSz6YKGIig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    iris_db.data,\n",
        "    iris_db.target,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        "    )\n",
        "x_train = torch.from_numpy(X_train.values).float()\n",
        "x_test = torch.from_numpy(X_test.values).float()\n",
        "\n",
        "y_train = torch.from_numpy(y_train.values).int()\n",
        "y_train = y_train.reshape(-1, 1)\n",
        "\n",
        "y_test = torch.from_numpy(y_test.values).int()\n",
        "y_test = y_test.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "u8Xc2EoqGS7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"maroon\"><u>**Q1.** We again notice that the attributes are on different scales. Use the normalisation method from last lab, to standardize the scales of each attribute on both sets. Plot the normalized and raw training sets; what do you observe? [2 marks] </font></u>"
      ],
      "metadata": {
        "id": "zZYG_EgHO9UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here\n",
        "\n"
      ],
      "metadata": {
        "id": "m1wT4i9sPE79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By inspecting the dataset we see that it contains 4 attributes. (`sepal length`, `sepal width`, `petal length`, `petal width`, in centimeters). For simplicity we will focus on the first two."
      ],
      "metadata": {
        "id": "Yh3ZsvKtEOzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris_db.data.iloc[:, :2]\n",
        "Y = iris_db.target\n",
        "marker_list = ['+', '.', 'x']\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_aspect('equal')\n",
        "\n",
        "for l in [0, 1, 2]:\n",
        "  ax.scatter(\n",
        "      X.loc[Y == l].iloc[:, 0],\n",
        "      X.loc[Y == l].iloc[:, 1],\n",
        "      marker=marker_list[l],\n",
        "      s=70,\n",
        "      color='black',\n",
        "      label='{:d} ({:s})'.format(l, iris_db.target_names[l])\n",
        "      )\n",
        "\n",
        "ax.legend(fontsize=12)\n",
        "ax.set_xlabel(iris_db.feature_names[0], fontsize=14)\n",
        "ax.set_ylabel(iris_db.feature_names[1], fontsize=14)\n",
        "ax.grid(alpha=0.3)\n",
        "ax.set_xlim(X.iloc[:, 0].min() - 0.5, X.iloc[:, 0].max() + 0.5)\n",
        "ax.set_ylim(X.iloc[:, 1].min() - 0.5, X.iloc[:, 1].max() + 0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hCHHwTkeEozi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the data linearly separable?"
      ],
      "metadata": {
        "id": "xfXF3tWrGzrE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As there are multiple classes, for now we will focus on class 0 (setosa). As such, we modify the `y_train` and `y_test` tensors, so that each label is 1 if the class is setosa and 0 if otherwise."
      ],
      "metadata": {
        "id": "jF07JTnlL9dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_1 = x_train[:, :2]\n",
        "test_set_1 = x_test[:, :2]\n",
        "\n",
        "# add a feature for bias\n",
        "train_set_1 = torch.cat([train_set_1, torch.ones(train_set_1.shape[0], 1)], dim=1)\n",
        "test_set_1 = torch.cat([test_set_1, torch.ones(test_set_1.shape[0], 1)], dim=1)\n",
        "\n",
        "setosa_train = (y_train == 0).int()\n",
        "setosa_test = (y_test == 0).int()"
      ],
      "metadata": {
        "id": "X6piRovBMwWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Sigmoid function\n",
        "With logistic regression the values we want to predict are now discrete classes, not continuous variables. In other words, logistic regression is for classification tasks. In the binary classification problem we have classes $0$ and $1$, e.g. classifying email as spam or not spam based on words used in the email.\n",
        "\n",
        "The logistic/sigmoid function given by the formula below:\n",
        "\n",
        "$ h_{\\theta}(x) = g(\\theta^{T}x) =  \\frac{1}{1+ e^{-\\theta^Tx}} $\n",
        "\n",
        "**Q2.** First implement the above function in `def sigmoid()`. [2 marks]\n",
        "\n",
        "**Q3.** Then, using the implementation of `LinearRegression` from last week as guideline, create a custom pytorch layer for `LogisticRegression` [2 marks]"
      ],
      "metadata": {
        "id": "dt7cyh74HdG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z: torch.Tensor) -> torch.Tensor:\n",
        "  ### your code here\n",
        "  return z\n",
        "\n",
        "\n",
        "x = torch.arange(1,2000, 1)/100.0 - 10\n",
        "y = sigmoid(x)\n",
        "fig, ax1 = plt.subplots()\n",
        "ax1.plot(x, y)\n",
        "# set label of horizontal axis\n",
        "ax1.set_xlabel('x')\n",
        "# set label of vertical axis\n",
        "ax1.set_ylabel('sigmoid(x)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Evt2Zt7_IiqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, num_features):\n",
        "    super().__init__()\n",
        "    self.weight = nn.Parameter(torch.zeros(1, num_features), requires_grad=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = 0\n",
        "    ### your code here\n",
        "    return y"
      ],
      "metadata": {
        "id": "Zg0DoqNDJuPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cost function we will use for logistic regression is the **Cross Entropy Loss**, which is given by the form:\n",
        "\n",
        "$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\left[ \\left(- y^{(i)} log( h_{\\theta}(x^{(i)})) - (1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))    \\right) \\right] $\n",
        "\n",
        "Which when taking partial derivatives and putting these into the gradient descent update equation gives\n",
        "\n",
        "\n",
        "$\n",
        " \\theta_{j} =  \\theta_{j} - \\alpha \\sum_{i=1}^m ( h_{\\theta}(x^{(i)}) - y^{(i)})x^{(i)}_{j}\n",
        "$\n",
        "\n",
        "**Q4.** Implement the cost in `bce()` and update the `gradient_descent_step()` from last week to update using the partial derivative above. [4 marks]"
      ],
      "metadata": {
        "id": "VycQ6JZMJlL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bce(y_true: torch.Tensor, y_pred: torch.Tensor) -> torch.Tensor:\n",
        "  ### your code here\n",
        "  return\n",
        "def gradient_descent_step(model: nn.Module, X: torch.Tensor, y: torch.Tensor, y_pred: torch.Tensor, lr: float) -> None:\n",
        "  weight = model.weight\n",
        "  N = X.shape[0]\n",
        "  ### your code here\n",
        "  ###\n",
        "  model.weight = nn.Parameter(weight, requires_grad=False)"
      ],
      "metadata": {
        "id": "EMSxdbNDLGoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, x, y, alpha):\n",
        "  cost_lst = list()\n",
        "  for it in range(1000):\n",
        "    prediction = model(x)\n",
        "    cost = bce(y, prediction)\n",
        "    cost_lst.append(cost)\n",
        "    gradient_descent_step(model, x, y, alpha)\n",
        "  display.clear_output(wait=True)\n",
        "  plt.plot(list(range(it+1)), cost_lst)\n",
        "  plt.show()\n",
        "  print(model.weight)\n",
        "  print('Minimum cost: {}'.format(min(cost_lst)))\n",
        "\n",
        "model = LogisticRegression(train_set_1.shape[1])\n",
        "alpha = 1 # select an appropriate lr\n",
        "train(model, train_set_1, setosa_train, alpha)"
      ],
      "metadata": {
        "id": "JBfC5qjINnZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u><font color=\"maroon\"> **Q5.** Draw the decision boundary on the test set using the learned parameters. Is this decision boundary separating the classes? Does this match our expectations? [2 marks]</font></u>"
      ],
      "metadata": {
        "id": "jiQpC_mUPzY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "hw3em9tjQKm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Multiclass\n",
        "So far, we have focused on a binary classification (is this iris setosa or not), however in this section we will address the problem as a multiclass classification. We will be using a 1 vs. all approach (refer to the lecture notes for details). We will also be using all 4 attributes for the classification.\n",
        "\n",
        "Firstly, we need to process `y_train, y_test` so that each label is a vector rather than an integer."
      ],
      "metadata": {
        "id": "qzmI5uoYUUjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = F.one_hot(y_train.reshape(-1).long(), num_classes=3)\n",
        "y_test = F.one_hot(y_test.reshape(-1).long(), num_classes=3)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "hWqTK02KXDZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section we will use the built in pytorch methods.\n"
      ],
      "metadata": {
        "id": "zXZ0edzSYA0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1\n",
        "setosa_model = nn.Sequential(nn.Linear(x_train.shape[1], 1, bias=False), nn.Sigmoid())\n",
        "setosa_labels = y_train[:, 0].reshape(-1, 1).float()\n",
        "setosa_testy = y_test[:, 0].reshape(-1, 1).float()\n",
        "optimiser = optim.SGD(setosa_model.parameters(), alpha)\n",
        "\n",
        "def train(model, x, y, test_x, test_y, optimiser, alpha):\n",
        "  train_lst = list()\n",
        "  test_lst = list()\n",
        "  for i in range(1000):\n",
        "    model.train()\n",
        "    optimiser.zero_grad()\n",
        "    pred = model(x)\n",
        "    cost = F.binary_cross_entropy(pred, y, reduction='mean')\n",
        "    cost.backward()\n",
        "    train_lst.append(cost.item())\n",
        "    optimiser.step()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      test_pred = model(test_x)\n",
        "      test_cost = F.binary_cross_entropy(test_pred, test_y, reduction='mean')\n",
        "      test_lst.append(test_cost)\n",
        "  fig, axs = plt.subplots(2)\n",
        "  axs[0].plot(list(range(i+1)), train_lst)\n",
        "  axs[1].plot(list(range(i+1)), test_lst)\n",
        "  plt.show()\n",
        "  print('Minimum train cost: {}'.format(min(train_lst)))\n",
        "  print('Minimum test cost: {}'.format(min(test_lst)))\n"
      ],
      "metadata": {
        "id": "qomtELIvbVoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(setosa_model, x_train, setosa_labels, x_test, setosa_testy, optimiser, alpha)"
      ],
      "metadata": {
        "id": "5i881XSDnya-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the cost of the 4 attribute model compare to the previous one?\n",
        "\n",
        "**Q6** Now train classifiers for the other two classes.[1 mark]"
      ],
      "metadata": {
        "id": "C4Y40xmeZACK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "qH1W2Vdvjf7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u><font color=\"maroon\"> **Q6.** Using the 3 classifiers, predict the classes of the samples in the test set and show the predictions in a table. Do you observe anything interesting? [4 marks] </font></u>"
      ],
      "metadata": {
        "id": "gF68dKcnpFhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### your code here"
      ],
      "metadata": {
        "id": "yAYXJYF5pVDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<u><font color=\"maroon\"> **Q7.** Calculate the accuracy of the classifier on the test set, by comparing the predicted values against the ground truth. Use a softmax for the classifier outputs. [1 mark] </font></u>"
      ],
      "metadata": {
        "id": "L2OsgEjh4qTH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zaOH_TMDo2R2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. The XOR problem\n",
        "\n",
        "<u><font color=\"maroon\"> **Q8.** Looking at the datapoints below, can we draw a decision boundary using Logistic Regression? Why? What are the specific issues or logistic regression with regards to XOR? [2 marks] </font></u>"
      ],
      "metadata": {
        "id": "Ao6Tdz7IrTIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = [0, 0, 1, 1]\n",
        "x2 = [0, 1, 0, 1]\n",
        "y = [0, 1, 1, 0]\n",
        "\n",
        "c_map = ['r', 'b', 'b', 'r']\n",
        "plt.scatter(x1, x2, c=c_map)\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N27DBvJHr-7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}